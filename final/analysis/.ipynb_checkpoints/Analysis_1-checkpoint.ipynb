{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Collection and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests,json,os\n",
    "import re,datetime\n",
    "import shutil\n",
    "import matplotlib.pyplot as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import http.client\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13df3e32632f4ebd90020eb9109ee05d\n"
     ]
    }
   ],
   "source": [
    "soccer_data_search_key = os.getenv('auth_key')\n",
    "print(soccer_data_search_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path='../data/raw_data'       #Creating directory.\n",
    "os.makedirs(dir_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for season in range(2015,2017):\n",
    "    connection = http.client.HTTPConnection('api.football-data.org') #Downloading data for a season from API using API key.            \n",
    "    headers = { 'X-Auth-Token': soccer_data_search_key, 'X-Response-Control': 'full' } \n",
    "    connection.request('GET', '/v1/competitions?season='+str(season), None, headers )\n",
    "    soc_data = json.loads(connection.getresponse().read().decode())\n",
    "    \n",
    "    season_path = os.path.join(dir_path, str(season)) #Creating folders for different seasons.  \n",
    "    os.makedirs(season_path,exist_ok=True)\n",
    "    \n",
    "#     print('\\n')\n",
    "#     print(season, len(soc_data))\n",
    "    for i in range(0,len(soc_data)): #Iterating through the season data and extracting competition names.\n",
    "        comp = re.sub(r'\\d{4}/\\d{2}', '', soc_data[i]['caption'])\n",
    "        comp = re.sub(r'\\d{4}', '', comp)\n",
    "#         print(comp)\n",
    "    \n",
    "        com_path = os.path.join(season_path, comp)   #Creating folders for different competitions.\n",
    "        os.makedirs(com_path,exist_ok=True)\n",
    "        \n",
    "        with open(comp,'w')as outfile: #Creating JSON files for each competition.\n",
    "            json.dump(soc_data[i],outfile)\n",
    "                       \n",
    "        team_path = os.path.join(dir_path, 'Teams')   # Creating folders for teams.\n",
    "        os.makedirs(team_path,exist_ok=True)\n",
    "        \n",
    "        connection = http.client.HTTPConnection('api.football-data.org') #Downloading data for a competition from API using API key.\n",
    "        headers = { 'X-Auth-Token': soccer_data_search_key, 'X-Response-Control': 'minified' }\n",
    "        connection.request('GET', '/v1/competitions/'+str(soc_data[i]['id'])+'/fixtures', None, headers )\n",
    "        fix_data = json.loads(connection.getresponse().read().decode())\n",
    "        \n",
    "        fix_path = os.path.join(com_path, 'Fixtures')   #Creating folders for fixture of different competitions.\n",
    "        os.makedirs(fix_path,exist_ok=True)\n",
    "        \n",
    "        for j in range(0,len(fix_data['fixtures'])): #Creating JSON files for each fixture.\n",
    "            fix=fix_data['fixtures'][j]['homeTeamName']+' .Vs. '+fix_data['fixtures'][j]['awayTeamName'] \n",
    "            try:\n",
    "                with open(fix,'w')as outfile:\n",
    "                    json.dump(fix_data['fixtures'][j],outfile)\n",
    "            except FileNotFoundError:\n",
    "                        pass\n",
    "        \n",
    "        for files in os.listdir('./'): #Iterating through each created JSON file and moving it to the appropriate location.\n",
    "            if not files.endswith('.ipynb'):\n",
    "                if not files.endswith('.ipynb_checkpoints' ):\n",
    "                    if ' .Vs. ' in files:\n",
    "                        try:\n",
    "                            shutil.move(os.path.join('./',files),os.path.join(fix_path,files+'.json'))\n",
    "                        except OSError:\n",
    "                            pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            shutil.move(os.path.join('./',files),os.path.join(com_path,files+'.json'))\n",
    "                        except OSError:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(dir_path):\n",
    "    if not root.endswith('/Fixtures'):\n",
    "        if not root.endswith('/Teams'): # Iterting through competiton JSON files.\n",
    "            for f in files:\n",
    "                if f.endswith('.json'):\n",
    "                    if not 'Table' in f:\n",
    "                        if not '.DS_Store' in f:\n",
    "                            with open(os.path.join(root,f), 'r', encoding='utf-8', errors=\"ignore\") as json_file:\n",
    "                                socdata=json.load(json_file) #Reading each JSON file\n",
    "\n",
    "                                comp = re.sub(r'\\d{4}/\\d{2}', '', socdata['caption'])\n",
    "                                comp = re.sub(r'\\d{4}', '', comp)\n",
    "\n",
    "                                connection = http.client.HTTPConnection('api.football-data.org') #Downloading table data of each competition using the comp ID.                       \n",
    "                                headers = { 'X-Auth-Token': soccer_data_search_key, 'X-Response-Control': 'minified' }\n",
    "                                connection.request('GET', '/v1/competitions/'+str(socdata['id'])+'/leagueTable', None, headers )\n",
    "                                table_data = json.loads(connection.getresponse().read().decode())\n",
    "                                \n",
    "                                sleep(2.2) #Delaying the loop by 2 second to limit the call rate.\n",
    "                                \n",
    "                                with open(comp +'Table','w')as outfile:\n",
    "                                    json.dump(table_data,outfile)    #Creating JSON files for each competition table.\n",
    "                                \n",
    "                                    for files in os.listdir('./'):\n",
    "                                        if not files.endswith('.ipynb'):  #Iterating through each created JSON file and moving it to the appropriate location.    \n",
    "                                            if not files.endswith('.ipynb_checkpoints' ):\n",
    "                                                if comp in files:\n",
    "                                                    try:\n",
    "                                                        shutil.move(os.path.join('./',files),os.path.join(root,files+'.json'))\n",
    "                                                    except OSError:\n",
    "                                                        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(dir_path):\n",
    "    if not root.endswith('/Fixtures'):\n",
    "        if not root.endswith('/Teams'):  # Iterting through competiton JSON files.\n",
    "            for f in files:\n",
    "                if f.endswith('.json'):\n",
    "                    if not 'Table' in f:\n",
    "                        if not '.DS_Store' in f:\n",
    "                            with open(os.path.join(root,f), 'r', encoding='utf-8', errors=\"ignore\") as json_file:\n",
    "                                socdata1=json.load(json_file) #Reading each JSON file which is not table data.\n",
    "                            \n",
    "                                connection = http.client.HTTPConnection('api.football-data.org')  #Downloading team data of each competition using the comp ID.\n",
    "                                headers = { 'X-Auth-Token': soccer_data_search_key, 'X-Response-Control': 'minified' }\n",
    "                                connection.request('GET', '/v1/competitions/'+str(socdata1['id'])+'/teams', None, headers )\n",
    "                                team_data = json.loads(connection.getresponse().read().decode())\n",
    "        \n",
    "                                for t in range(0,len(team_data['teams'])):\n",
    "                                    try:\n",
    "                                        with open('Team: '+team_data['teams'][t]['name'],'w')as outfile:\n",
    "                                            json.dump(team_data['teams'][t],outfile)  #Creating JSON files for each team.\n",
    "\n",
    "                                    except FileNotFoundError:\n",
    "                                        pass\n",
    "                                    \n",
    "                                    for files in os.listdir('./'):\n",
    "                                        if not files.endswith('.ipynb'):  #Iterating through each created JSON file and moving it to the appropriate location.      \n",
    "                                            if not files.endswith('.ipynb_checkpoints' ):\n",
    "                                                if 'Team: ' in files:\n",
    "                                                    try:\n",
    "                                                        shutil.move(os.path.join('./',files),os.path.join(dir_path+'/Teams',files+'.json'))\n",
    "                                                    except OSError:\n",
    "                                                        pass\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
